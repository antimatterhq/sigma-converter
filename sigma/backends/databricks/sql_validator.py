from typing import List

import sqlglot

databricks_functions = [
    "abs",
    "acos",
    "acosh",
    "add_months",
    "aes_decrypt",
    "aes_encrypt",
    "aggregate",
    "ai_analyze_sentiment",
    "ai_classify",
    "ai_extract",
    "ai_fix_grammar",
    "ai_forecast",
    "ai_gen",
    "ai_generate_text",
    "ai_mask",
    "ai_query",
    "ai_similarity",
    "ai_summarize",
    "ai_translate",
    "any_value",
    "approx_count_distinct",
    "approx_percentile",
    "approx_top_k",
    "array",
    "array_agg",
    "array_append",
    "array_compact",
    "array_contains",
    "array_distinct",
    "array_except",
    "array_insert",
    "array_intersect",
    "array_join",
    "array_max",
    "array_min",
    "array_position",
    "array_prepend",
    "array_remove",
    "array_repeat",
    "array_size",
    "array_sort",
    "array_union",
    "arrays_overlap",
    "arrays_zip",
    "ascii",
    "asin",
    "asinh",
    "assert_true",
    "atan",
    "atan2",
    "atanh",
    "avg",
    "base64",
    "between",
    "bigint",
    "bin",
    "binary",
    "bit_and",
    "bit_count",
    "bit_get",
    "bit_length",
    "bit_or",
    "bit_reverse",
    "bit_xor",
    "bitmap_bucket_number",
    "bitmap_bit_position",
    "bitmap_construct_agg",
    "bitmap_count",
    "bitmap_or_agg",
    "bool_and",
    "bool_or",
    "boolean",
    "bround",
    "btrim",
    "call_function",
    "call_udf",
    "cardinality",
    "case",
    "cast",
    "cbrt",
    "ceil",
    "ceiling",
    "char",
    "char_length",
    "character_length",
    "chr",
    "cloud_files_state",
    "coalesce",
    "collate",
    "collect_list",
    "collect_set",
    "concat",
    "concat_ws",
    "contains",
    "conv",
    "convert_timezone",
    "corr",
    "cos",
    "cosh",
    "cot",
    "count",
    "count_if",
    "count_min_sketch",
    "covar_pop",
    "covar_samp",
    "crc32",
    "csc",
    "cume_dist",
    "current_catalog",
    "current_database",
    "current_date",
    "current_metastore",
    "current_schema",
    "current_timestamp",
    "current_timezone",
    "current_user",
    "current_version",
    "date",
    "date_add",
    "date_diff",
    "date_format",
    "date_from_unix_date",
    "date_part",
    "date_sub",
    "date_trunc",
    "dateadd",
    "datepart",
    "datediff",
    "day",
    "dayofmonth",
    "dayofweek",
    "dayofyear",
    "decimal",
    "decode",
    "degrees",
    "dense_rank",
    "double",
    "e",
    "element_at",
    "elt",
    "encode",
    "endswith",
    "equal_null",
    "every",
    "exists",
    "exp",
    "explode",
    "explode_outer",
    "expm1",
    "extract",
    "factorial",
    "filter",
    "find_in_set",
    "first",
    "first_value",
    "flatten",
    "float",
    "floor",
    "forall",
    "format_number",
    "format_string",
    "from_csv",
    "from_json",
    "from_unixtime",
    "from_utc_timestamp",
    "get",
    "get_json_object",
    "getbit",
    "greatest",
    "grouping",
    "grouping_id",
    "h3_boundaryasgeojson",
    "h3_boundaryaswkb",
    "h3_boundaryaswkt",
    "h3_centerasgeojson",
    "h3_centeraswkb",
    "h3_centeraswkt",
    "h3_cellarea",
    "h3_compact",
    "h3_coverash3",
    "h3_coverash3string",
    "h3_distance",
    "h3_h3tostring",
    "h3_hexring",
    "h3_ischildof",
    "h3_ispentagon",
    "h3_isvalid",
    "h3_kring",
    "h3_kringdistances",
    "h3_longlatash3",
    "h3_longlatash3string",
    "h3_maxchild",
    "h3_minchild",
    "h3_parent",
    "h3_pointash3",
    "h3_pointash3string",
    "h3_polyfillasgeojson",
    "h3_polyfillash3",
    "h3_polyfillash3string",
    "h3_polyfillaswkb",
    "h3_polyfillaswkt",
    "h3_resolution",
    "h3_stringtoh3",
    "h3_tochildren",
    "h3_toparent",
    "h3_try_distance",
    "h3_try_polyfillash3",
    "h3_try_polyfillash3string",
    "h3_try_validate",
    "h3_uncompact",
    "h3_validate",
    "hash",
    "hex",
    "histogram_numeric",
    "hll_sketch_agg",
    "hll_sketch_estimate",
    "hll_union",
    "hll_union_agg",
    "hour",
    "hypot",
    "if",
    "ifnull",
    "ilike",
    "in",
    "initcap",
    "inline",
    "inline_outer",
    "input_file_block_length",
    "input_file_block_start",
    "input_file_name",
    "instr",
    "int",
    "is_member",
    "is_account_group_member",
    "isnan",
    "isnotnull",
    "isnull",
    "java_method",
    "json_array_length",
    "json_object_keys",
    "json_tuple",
    "julianday",
    "kurtosis",
    "lag",
    "last",
    "last_day",
    "last_value",
    "lcase",
    "lead",
    "least",
    "left",
    "len",
    "length",
    "levenshtein",
    "like",
    "list_secrets",
    "ln",
    "localtimestamp",
    "locate",
    "log",
    "log10",
    "log1p",
    "log2",
    "lower",
    "lpad",
    "ltrim",
    "luhn_check",
    "make_date",
    "make_dt_interval",
    "make_interval",
    "make_timestamp",
    "make_timestamp_ltz",
    "make_timestamp_ntz",
    "make_ym_interval",
    "map",
    "map_concat",
    "map_contains_key",
    "map_entries",
    "map_filter",
    "map_from_arrays",
    "map_from_entries",
    "map_keys",
    "map_values",
    "map_zip_with",
    "mask",
    "max",
    "max_by",
    "md5",
    "mean",
    "median",
    "min",
    "min_by",
    "minute",
    "mod",
    "mode",
    "monotonically_increasing_id",
    "month",
    "months_between",
    "named_struct",
    "nanvl",
    "neg",
    "negative",
    "next_day",
    "not",
    "now",
    "nth_value",
    "ntile",
    "nullif",
    "nullifzero",
    "nvl",
    "nvl2",
    "octet_length",
    "or",
    "overlay",
    "parse_url",
    "percent_rank",
    "percentile",
    "percentile_approx",
    "percentile_cont",
    "percentile_disc",
    "pi",
    "pmod",
    "posexplode",
    "posexplode_outer",
    "position",
    "positive",
    "pow",
    "power",
    "printf",
    "quarter",
    "radians",
    "raise_error",
    "rand",
    "randn",
    "random",
    "range",
    "rank",
    "read_files",
    "reduce",
    "reflect",
    "regexp",
    "regexp_count",
    "regexp_extract",
    "regexp_extract_all",
    "regexp_instr",
    "regexp_like",
    "regexp_replace",
    "regexp_substr",
    "regr_avgx",
    "regr_avgy",
    "regr_count",
    "regr_intercept",
    "regr_r2",
    "regr_slope",
    "regr_sxx",
    "regr_sxy",
    "regr_syy",
    "repeat",
    "replace",
    "reverse",
    "right",
    "rint",
    "rlike",
    "round",
    "row_number",
    "rpad",
    "rtrim",
    "schema_of_csv",
    "schema_of_json",
    "sec",
    "second",
    "secret",
    "sentences",
    "sequence",
    "session_user",
    "sha",
    "sha1",
    "sha2",
    "shiftleft",
    "shiftright",
    "shiftrightunsigned",
    "shuffle",
    "sign",
    "signum",
    "sin",
    "sinh",
    "size",
    "skewness",
    "slice",
    "smallint",
    "some",
    "sort_array",
    "soundex",
    "space",
    "spark_partition_id",
    "split",
    "split_part",
    "sqrt",
    "st_area",
    "st_asbinary",
    "st_asgeojson",
    "st_astext",
    "st_aswkb",
    "st_aswkt",
    "st_buffer",
    "st_centroid",
    "st_contains",
    "st_convexhull",
    "st_coorddim",
    "st_crosses",
    "st_difference",
    "st_dimension",
    "st_disjoint",
    "st_distance",
    "st_distancesphere",
    "st_distancespheroid",
    "st_dump",
    "st_dwithin",
    "st_endpoint",
    "st_envelope",
    "st_equals",
    "st_exteriorring",
    "st_flipcoordinates",
    "st_force2d",
    "st_geohash",
    "st_geomcollfromtext",
    "st_geomcollfromwkb",
    "st_geometryfromtext",
    "st_geometryn",
    "st_geometrytype",
    "st_geomfromgeohash",
    "st_geomfromgeojson",
    "st_geomfromtext",
    "st_geomfromwkb",
    "st_geomfromwkt",
    "st_haversine",
    "st_hausdorffdistance",
    "st_interiorringn",
    "st_intersection",
    "st_intersects",
    "st_is_valid",
    "st_isclosed",
    "st_isempty",
    "st_ispolygonccw",
    "st_ispolygoncw",
    "st_isring",
    "st_issimple",
    "st_isvalid",
    "st_length",
    "st_length2dsphere",
    "st_lengthspheroid",
    "st_linefromtext",
    "st_linefromwkb",
    "st_linemerge",
    "st_linestringfromtext",
    "st_linestringfromwkb",
    "st_makeline",
    "st_makepoint",
    "st_makepolygon",
    "st_maxdistance",
    "st_mindistance",
    "st_mlinefromtext",
    "st_mlinefromwkb",
    "st_mpointfromtext",
    "st_mpointfromwkb",
    "st_mpolyfromtext",
    "st_mpolyfromwkb",
    "st_multi",
    "st_multilinestringfromtext",
    "st_multilinestringfromwkb",
    "st_multipointfromtext",
    "st_multipointfromwkb",
    "st_multipolygonfromtext",
    "st_multipolygonfromwkb",
    "st_ndims",
    "st_npoints",
    "st_nrings",
    "st_numgeometries",
    "st_numinteriorrings",
    "st_numpoints",
    "st_orderingequals",
    "st_overlaps",
    "st_perimeter",
    "st_point",
    "st_pointatparameter",
    "st_pointfromgeohash",
    "st_pointfromtext",
    "st_pointfromwkb",
    "st_pointn",
    "st_pointonsurface",
    "st_polyfromtext",
    "st_polyfromwkb",
    "st_polygon",
    "st_polygonfromtext",
    "st_polygonfromwkb",
    "st_project",
    "st_reduceprecision",
    "st_relate",
    "st_removepoint",
    "st_removerepeatedpoints",
    "st_reverse",
    "st_rotate",
    "st_s2cellidstokring",
    "st_s2cellidstoringinterior",
    "st_scale",
    "st_setpoint",
    "st_setsrid",
    "st_shift",
    "st_shiftlongitude",
    "st_simplify",
    "st_snap",
    "st_snaptoself",
    "st_srid",
    "st_startpoint",
    "st_symdifference",
    "st_touches",
    "st_transform",
    "st_translate",
    "st_triangulate",
    "st_union",
    "st_unaryunion",
    "st_within",
    "st_x",
    "st_xmax",
    "st_xmin",
    "st_y",
    "st_ymax",
    "st_ymin",
    "st_z",
    "st_zmax",
    "st_zmin",
    "stack",
    "startswith",
    "std",
    "stddev",
    "stddev_pop",
    "stddev_samp",
    "str_to_map",
    "string",
    "struct",
    "substr",
    "substring",
    "substring_index",
    "sum",
    "system_time",
    "t_digest_agg",
    "t_digest_percentile",
    "tan",
    "tanh",
    "time_window",
    "timestamp",
    "timestamp_micros",
    "timestamp_millis",
    "timestamp_seconds",
    "timestampadd",
    "timestampdiff",
    "tinyint",
    "to_avro",
    "to_binary",
    "to_csv",
    "to_date",
    "to_json",
    "to_number",
    "to_protobuf",
    "to_timestamp",
    "to_timestamp_ltz",
    "to_timestamp_ntz",
    "to_unix_timestamp",
    "to_utc_timestamp",
    "to_varchar",
    "to_xml",
    "to_char",
    "transform",
    "transform_keys",
    "transform_values",
    "translate",
    "trim",
    "trunc",
    "try_add",
    "try_aes_decrypt",
    "try_avg",
    "try_cast",
    "try_divide",
    "try_element_at",
    "try_multiply",
    "try_parse_json",
    "try_reflect",
    "try_subtract",
    "try_sum",
    "try_to_binary",
    "try_to_date",
    "try_to_number",
    "try_to_timestamp",
    "try_url_decode",
    "typeof",
    "ucase",
    "unbase64",
    "unhex",
    "uniform",
    "unix_date",
    "unix_micros",
    "unix_millis",
    "unix_seconds",
    "unix_timestamp",
    "unwrap_udt",
    "upper",
    "url_decode",
    "url_encode",
    "user",
    "uuid",
    "var_pop",
    "var_samp",
    "variance",
    "version",
    "void",
    "weekday",
    "weekofyear",
    "when",
    "width_bucket",
    "window",
    "window_time",
    "xpath",
    "xpath_boolean",
    "xpath_double",
    "xpath_float",
    "xpath_int",
    "xpath_long",
    "xpath_number",
    "xpath_short",
    "xpath_string",
    "xxhash64",
    "year",
    "zeroifnull",
    "zip_with",
]


def check_funcs(funcs: List[str]) -> List[str]:
    """Check if SQL functions are valid for Databricks/Spark.

    Args:
        funcs: List of function names to check

    Returns:
        List of error messages for invalid functions
    """
    errors = []
    for f in funcs:
        if f not in databricks_functions:
            errors.append(f"SQL contains a function that is not valid in Spark SQL: {f}")
    return errors


def verify_databricks_sql(query: str) -> List[str]:
    """
    Verify the passed query is a valid databricks SQL. This works with partial SQL as well for example
    one can provide only WHERE conditions without a SELECT part.

    Args:
        query: SQL string to check

    Returns:
        List of error messages in case the query is invalid otherwise an empty list is returned.
    """
    errors = []
    try:
        ast = sqlglot.parse_one(query, read="spark")
        # Extract function names
        func_nodes = ast.find_all(sqlglot.exp.Func)
        funcs = sorted({f.name for f in func_nodes if f.key == "anonymous"})
        errors.extend(check_funcs(funcs))
    except Exception as e:
        errors.append(f"Query is not valid Databricks SQL: {str(e)}")

    return errors
